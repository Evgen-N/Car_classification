{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Классификация изображений"},{"metadata":{},"cell_type":"markdown","source":" Цель этого проекта - первое практическое знакомство с нейросетями и применение простых приемов для улучшения результата работы собранной нейросети.  \n \n Краткая схема действий:\n \n 1. Загрузка библиотек и данных  \n 2. Предварительный анализ даннных\n 3. Аугментация данных с использованием библиотеки Albumentations и подготовка генераторов данных\n 4. Transfer Learning - построение нейросети с использованием в качестве основы предобученной на Imagenet сети EfficientNetB6\n 5. Fine Tuning - последовательное включение в работу слоев сети EfficientNetB6 (0% - 50% -100%)\n 6. Подбор Learning Rate вручную и через callbacks, подбор optimizer\n 7. Увеличение размера подаваемых изображений на последнем этапе обучения сети для повышения точности\n 8. Test Time Augmentation (TTA) для усреднения нескольких предиктов и исключения случайных ошибок\n\n Основой для проекта послужили ноутбуки  BaseLine и transfer-learning-keras-flowers-sf-dl-v2 из курса. "},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"!nvidia-smi","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install -U efficientnet","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_kg_hide-input":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pickle\nimport zipfile\nimport csv\nimport sys\nimport os\nimport math\n\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import LearningRateScheduler, ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\nfrom tensorflow.keras.callbacks import Callback\nfrom tensorflow.keras.regularizers import l2\nfrom tensorflow.keras import optimizers\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.applications.xception import Xception\nfrom tensorflow.keras.layers import *\n\nfrom sklearn.model_selection import train_test_split, StratifiedKFold\n\nimport tensorflow.keras.models as M\nimport tensorflow.keras.layers as L\nimport tensorflow.keras.backend as K\nimport tensorflow.keras.callbacks as C\nimport efficientnet.tfkeras as efn\n\nimport PIL\nfrom PIL import ImageOps, ImageFilter\n#увеличим дефолтный размер графиков\nfrom pylab import rcParams\nrcParams['figure.figsize'] = 10, 5\n#графики в svg выглядят более четкими\n%config InlineBackend.figure_format = 'svg' \n%matplotlib inline\n\nprint(os.listdir(\"../input\"))\nprint('Python       :', sys.version.split('\\n')[0])\nprint('Numpy        :', np.__version__)\nprint('Tensorflow   :', tf.__version__)\nprint('Keras        :', tf.keras.__version__)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Работаем с Tensorflow v2**"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"!pip freeze > requirements.txt","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Основные настройки"},{"metadata":{"trusted":true},"cell_type":"code","source":"EPOCHS               = 5  # эпох на обучение\nBATCH_SIZE           = 64 # уменьшаем batch если сеть большая, иначе не влезет в память на GPU\nLR                   = 0.001\nVAL_SPLIT            = 0.15 # сколько данных выделяем на тест = 15%\n\nCLASS_NUM            = 10  # количество классов в нашей задаче\nIMG_SIZE             = 224 # какого размера подаем изображения в сеть\nIMG_CHANNELS         = 3   # у RGB 3 канала\ninput_shape          = (IMG_SIZE, IMG_SIZE, IMG_CHANNELS)\n\nDATA_PATH = '../input/sf-dl-car-classification/'\nPATH = \"../working/car/\" # рабочая директория","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"# Устаналиваем конкретное значение random seed для воспроизводимости\nos.makedirs(PATH,exist_ok=False)\n\nRANDOM_SEED = 42\nnp.random.seed(RANDOM_SEED)  \nPYTHONHASHSEED = 0","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# EDA / Анализ данных"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = pd.read_csv(DATA_PATH+\"train.csv\")\nsample_submission = pd.read_csv(DATA_PATH+\"sample-submission.csv\")\ntrain_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.Category.value_counts()\n# распределение классов достаточно равномерное - это хорошо","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Распаковываем картинки')\n\nfor data_zip in ['train.zip', 'test.zip']:\n    with zipfile.ZipFile(DATA_PATH+data_zip,\"r\") as z:\n        z.extractall(PATH)\n        \nprint(os.listdir(PATH))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Примеры изображений по классам\nfor category in range(10):\n    plt.figure(figsize=(16, 4))\n\n    cat_image = train_df[train_df['Category'] == category].sample(4)\n    cat_image_paths = cat_image['Id'].values\n    cat_image_cat = cat_image['Category'].values\n\n    for index, path in enumerate(cat_image_paths):\n        im = PIL.Image.open(PATH+f'train/{cat_image_cat[index]}/{path}')\n        plt.subplot(1,4, index+1)\n        plt.imshow(im)\n        plt.title('Class: '+str(cat_image_cat[index]))\n        plt.axis('off')\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Видим, что классы соответствуют разным моделям/маркам автомобилей: класс 1 - форд \"Фокус\", класс 8 - фольксваген \"Пассат\", остальные - \nэто 8 разных моделей ВАЗ. Фото различаются по размерам, яркости, четкости, ракурсам, перспективе и тд.  \nПри аугментации можем использовать все эти преобразования."},{"metadata":{"trusted":true},"cell_type":"code","source":"image = PIL.Image.open(PATH+'/train/0/100380.jpg')\nimgplot = plt.imshow(image)\nplt.show()\nimage.size","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Подготовка данных"},{"metadata":{},"cell_type":"markdown","source":"### Аугментация данных"},{"metadata":{},"cell_type":"markdown","source":"Для аугментации данных используем библиотеку Albumentations"},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install git+https://github.com/mjkvaak/ImageDataAugmentor","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from ImageDataAugmentor.image_data_augmentor import *\nimport albumentations as A","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Собираем набор преобразований исходных изображений"},{"metadata":{"trusted":true},"cell_type":"code","source":"AUG = A.Compose([\n    A.HorizontalFlip(p=0.25),\n    A.ToGray(p=0.15),\n#    A.ToSepia(p=0.25),\n    A.OneOf([\n        A.RandomBrightnessContrast(brightness_limit=0.3, contrast_limit=0.3),\n        A.RandomBrightnessContrast(brightness_limit=0.1, contrast_limit=0.1)\n    ],p=0.35),\n    A.ShiftScaleRotate(always_apply=False, p=0.5, shift_limit=(-0.06, 0.06), rotate_limit=(-10, 10), interpolation=0, border_mode=0, value=(0, 0, 0), mask_value=None),\n    A.GaussianBlur(p=0.05),\n    A.HueSaturationValue(p=0.25),\n    A.RandomShadow(shadow_roi=(0, 0.5, 1, 1), num_shadows_lower=1, num_shadows_upper=2, shadow_dimension=5, always_apply=False, p=0.25),\n])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_datagen = ImageDataAugmentor(\n        rescale=1./255,\n        augment=AUG,\n        validation_split=VAL_SPLIT\n)\ntest_datagen = ImageDataAugmentor(rescale=1./255)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Генерация данных"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Завернем наши данные в генератор:\ntrain_generator = train_datagen.flow_from_directory(\n        PATH+'train/',\n        target_size=(IMG_SIZE, IMG_SIZE),\n        batch_size=BATCH_SIZE,\n        class_mode='categorical',\n        shuffle=True, seed=RANDOM_SEED,\n        subset='training')        # set as training data\ntest_generator = train_datagen.flow_from_directory(\n        PATH+'train/',\n        target_size=(IMG_SIZE, IMG_SIZE),\n        batch_size=BATCH_SIZE,\n        class_mode='categorical',\n        shuffle=True, seed=RANDOM_SEED,\n        subset='validation')      # set as validation data\ntest_sub_generator = test_datagen.flow_from_dataframe( \n        dataframe=sample_submission,\n        directory=PATH+'test_upload/',\n        x_col=\"Id\",\n        y_col=None,\n        shuffle=False,\n        class_mode=None,\n        seed=RANDOM_SEED,\n        target_size=(IMG_SIZE, IMG_SIZE),\n        batch_size=BATCH_SIZE)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''train_datagen = ImageDataGenerator(\n    rescale=1. / 255,\n    rotation_range = 5,\n#    shear_range=0.15,\n    zoom_range=[0.85,1.15],\n    brightness_range=[0.5, 1.5],\n    width_shift_range=0.1,\n    height_shift_range=0.1,\n    validation_split=VAL_SPLIT, # set validation split\n    horizontal_flip=False,\n#    fill_mode=\"nearest\",\n)\n\ntest_datagen = ImageDataGenerator(rescale=1. / 255)'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''train_generator = train_datagen.flow_from_directory(\n    PATH+'train/',      # директория где расположены папки с картинками \n    target_size=(IMG_SIZE, IMG_SIZE),\n    batch_size=BATCH_SIZE,\n    class_mode='categorical',\n    shuffle=True, seed=RANDOM_SEED,\n    subset='training') # set as training data\n\ntest_generator = train_datagen.flow_from_directory(\n    PATH+'train/',\n    target_size=(IMG_SIZE, IMG_SIZE),\n    batch_size=BATCH_SIZE,\n    class_mode='categorical',\n    shuffle=True, seed=RANDOM_SEED,\n    subset='validation') # set as validation data\n\ntest_sub_generator = test_datagen.flow_from_dataframe( \n    dataframe=sample_submission,\n    directory=PATH+'test_upload/',\n    x_col=\"Id\",\n    y_col=None,\n    shuffle=False,\n    class_mode=None,\n    seed=RANDOM_SEED,\n    target_size=(IMG_SIZE, IMG_SIZE),\n    batch_size=BATCH_SIZE,)'''","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Построение модели"},{"metadata":{},"cell_type":"markdown","source":"### Загружаем предобученную сеть EfficientNetB6:"},{"metadata":{"trusted":true},"cell_type":"code","source":"input_shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"base_model = efn.EfficientNetB6(weights='imagenet', include_top=False, input_shape=input_shape)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"base_model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Не тренируем базовую модель на первом этапе\nbase_model.trainable = False","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Собираем нейросеть: к базовой EfficientNetB6 добавляем два плотных слоя, второй из них - непосредственно для классификации.  \nИспользуем также вспомогательные Pooling и Dropout слои, а также BatchNormalization"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Making Model\nmodel=M.Sequential()\nmodel.add(base_model)\nmodel.add(BatchNormalization())\nmodel.add(L.GlobalAveragePooling2D())\n#model.add(L.Dropout(0.25))\n#model.add(L.Flatten())\nmodel.add(L.Dense(256, activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(L.Dropout(0.25))     # or 0.5\nmodel.add(L.Dense(CLASS_NUM, activation='softmax'))","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":false,"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# How many layers\nprint(len(model.layers))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(model.trainable_variables)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check the trainable status of the individual layers\nfor layer in model.layers:\n    print(layer, layer.trainable)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Обучение модели"},{"metadata":{},"cell_type":"markdown","source":"# Step 1"},{"metadata":{},"cell_type":"markdown","source":"# No Power CNN"},{"metadata":{"trusted":true},"cell_type":"code","source":"LR = 0.001\nEPOCHS = 5\nmodel.compile(loss=\"categorical_crossentropy\", optimizer=optimizers.Adam(lr=LR), metrics=[\"accuracy\"])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Добавим ModelCheckpoint, чтобы сохранять прогресс обучения модели и можно было потом подгрузить и дообучить модель, и  \nEarlyStopping на будущее"},{"metadata":{"trusted":true},"cell_type":"code","source":"checkpoint = ModelCheckpoint('best_model.hdf5' , monitor = ['val_accuracy'] , verbose = 1  , mode = 'max')\nearlystop = EarlyStopping(monitor='val_accuracy', patience=5, restore_best_weights=True,verbose=1)\n#reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2, min_lr=0.00001)\ncallbacks_list = [checkpoint, earlystop]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Обучаем:"},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model.fit(\n                    train_generator,\n                    steps_per_epoch = train_generator.samples//train_generator.batch_size,\n#                    steps_per_epoch = len(train_generator),\n                    validation_data = test_generator, \n                    validation_steps = test_generator.samples//test_generator.batch_size,\n#                    validation_steps = len(test_generator),\n                    epochs = EPOCHS,\n                    callbacks = callbacks_list\n                    )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Подгрузим лучшую итерацию в обучении (best_model)\nmodel.save('../working/model_step1.hdf5')\nmodel.load_weights('best_model.hdf5')","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"# Посмотрим точность на этом шаге\nscores = model.evaluate(test_generator, verbose=1)\nprint(\"Accuracy: %.2f%%\" % (scores[1]*100))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_history(history):\n    plt.figure(figsize=(10,5))\n    #plt.style.use('dark_background')\n    acc = history.history['accuracy']\n    val_acc = history.history['val_accuracy']\n    loss = history.history['loss']\n    val_loss = history.history['val_loss']\n\n    epochs = range(len(acc))\n\n    plt.plot(epochs, acc, 'b', label='Training acc')\n    plt.plot(epochs, val_acc, 'g', label='Validation acc')\n    plt.title('Training and validation accuracy')\n    plt.legend()\n\n    #plt.figure()\n    plt.figure(figsize=(10,5))\n    #plt.style.use('dark_background')\n    plt.plot(epochs, loss, 'b', label='Training loss')\n    plt.plot(epochs, val_loss, 'g', label='Validation loss')\n    plt.title('Training and validation loss')\n    plt.legend()\n\n    plt.show()\n\nplot_history(history)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"На этом этапе достигается точность порядка 0.70 "},{"metadata":{},"cell_type":"markdown","source":"# Step 2"},{"metadata":{},"cell_type":"markdown","source":"# Half Power CNN"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Number of layers in the base model: \", len(base_model.layers))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Разморозим половину слоев базовой нейросети"},{"metadata":{"trusted":true},"cell_type":"code","source":"base_model.trainable = True\n\n# Fine-tune from this layer onwards\nfine_tune_at = len(base_model.layers)//2\n\n# Freeze all the layers before the `fine_tune_at` layer\nfor layer in base_model.layers[:fine_tune_at]:\n    layer.trainable =  False\nlen(base_model.trainable_variables)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check the trainable status of the individual layers\nfor layer in model.layers:\n    print(layer, layer.trainable)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Изменим гиперпараметры\nLR=0.0001\nEPOCHS = 10\nmodel.compile(loss=\"categorical_crossentropy\", optimizer=optimizers.Adam(lr=LR), metrics=[\"accuracy\"])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Добавим LearningRateScheduler для управления LR в ходе обучения.  \nПопробуем профиль с небольшим холмом, чтобы выйти из возможного локального минимума"},{"metadata":{"trusted":true},"cell_type":"code","source":"# LearningRateScheduler - HandMade\nlr_list = [1e-03, 2e-03, 5e-03, 2e-03, 1e-03, 5e-04, 2.5e-04, 1e-04, 1e-04, 5e-05]\ndef schedule(epoch):\n    return lr_list[epoch]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"checkpoint = ModelCheckpoint('best_model.hdf5' , monitor = ['val_accuracy'] , verbose = 1  , mode = 'max')\nearlystop = EarlyStopping(monitor='val_accuracy', patience=5, restore_best_weights=True, verbose=1)\nlr_scheduler = LearningRateScheduler(schedule, verbose=1)\ncallbacks_list = [checkpoint, earlystop, lr_scheduler]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Обучаем\nhistory = model.fit(\n        train_generator,\n        steps_per_epoch = train_generator.samples//train_generator.batch_size,\n        validation_data = test_generator, \n        validation_steps = test_generator.samples//test_generator.batch_size,\n        epochs = EPOCHS,\n        callbacks = callbacks_list\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.save('../working/model_step2.hdf5')\nmodel.load_weights('best_model.hdf5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scores = model.evaluate(test_generator, verbose=1)\nprint(\"Accuracy: %.2f%%\" % (scores[1]*100))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_history(history)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"На этом этапе достигается точность 0.940 - 0.945  \nЗатраты времени на первые два этапа - 100 минут"},{"metadata":{},"cell_type":"markdown","source":"# Step 3"},{"metadata":{},"cell_type":"markdown","source":"# Full Power CNN"},{"metadata":{},"cell_type":"markdown","source":"Включаем базовую модель на 100% и уменьшаем BATCH_SIZE до 16, чтобы не перегрузить GPU."},{"metadata":{"trusted":true},"cell_type":"code","source":"base_model.trainable = True","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"BATCH_SIZE = 16\nLR=0.00001\nEPOCHS = 10","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Переопределяем генератор данных, чтобы учесть изменение размера батча"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_generator = train_datagen.flow_from_directory(\n    PATH+'train/',      # директория где расположены папки с картинками \n    target_size=(IMG_SIZE, IMG_SIZE),\n    batch_size=BATCH_SIZE,\n    class_mode='categorical',\n    shuffle=True, seed=RANDOM_SEED,\n    subset='training') # set as training data\n\ntest_generator = train_datagen.flow_from_directory(\n    PATH+'train/',\n    target_size=(IMG_SIZE, IMG_SIZE),\n    batch_size=BATCH_SIZE,\n    class_mode='categorical',\n    shuffle=True, seed=RANDOM_SEED,\n    subset='validation') # set as validation data\n\ntest_sub_generator = test_datagen.flow_from_dataframe( \n    dataframe=sample_submission,\n    directory=PATH+'test_upload/',\n    x_col=\"Id\",\n    y_col=None,\n    shuffle=False,\n    class_mode=None,\n    seed=RANDOM_SEED,\n    target_size=(IMG_SIZE, IMG_SIZE),\n    batch_size=BATCH_SIZE,)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(loss=\"categorical_crossentropy\", optimizer=optimizers.Adam(lr=LR), metrics=[\"accuracy\"])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Пробуем разные LearningRateScheduler из callbacks"},{"metadata":{"trusted":true},"cell_type":"code","source":"'''# LearningRateScheduler - Exponential Decay\n# Define configuration parameters\nstart_lr = LR\nexp_decay = 0.33\n\n# Define the scheduling function\ndef schedule(epoch):\n    def lr(epoch, start_lr, exp_decay):\n        return start_lr * math.exp(-exp_decay*epoch)\n    return lr(epoch, start_lr, exp_decay)'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''# LearningRateScheduler - HandMade\nlr_list = [5e-5, 5e-5, 7e-5, 8e-5, 3e-5, 2e-5, 1.5e-5, 1e-5, 4e-5, 2.5e-5, 2e-5, 1e-5, 1e-5, 5e-6, 5e-6]\ndef schedule(epoch):\n    return lr_list[epoch]'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# LearningRateScheduler - One CLR\n# LR растет от start_lr линейно rampup_epochs эпох до max_lr, затем 3 делает шага на max_lr, далее убывает по экспоненте не очень круто в сторону min_lr \n# Define configuration parameters\nstart_lr = 0.00001\nmin_lr = 0.000001\nmax_lr = 0.0001\nrampup_epochs = 4\nsustain_epochs = 2\nexp_decay = 0.8\n\n# Define the scheduling function\ndef schedule(epoch):\n    def lr(epoch, start_lr, min_lr, max_lr, rampup_epochs, sustain_epochs, exp_decay):\n        if epoch < rampup_epochs:\n            lr = (max_lr - start_lr)/rampup_epochs * epoch + start_lr\n        elif epoch < rampup_epochs + sustain_epochs:\n            lr = max_lr\n        else:\n            lr = (max_lr - min_lr) * exp_decay**(epoch-rampup_epochs-sustain_epochs) + min_lr\n        return lr\n    return lr(epoch, start_lr, min_lr, max_lr, rampup_epochs, sustain_epochs, exp_decay)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"checkpoint = ModelCheckpoint('best_model.hdf5' , monitor = ['val_accuracy'] , verbose = 1  , mode = 'max')\nearlystop = EarlyStopping(monitor='val_accuracy', patience=5, restore_best_weights=True, verbose=1)\nlr_scheduler = LearningRateScheduler(schedule, verbose=1)\ncallbacks_list = [checkpoint, earlystop, lr_scheduler]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#from tensorflow import keras\n#model = keras.models.load_model(\"../working/last_model/\")\n#model = M.load_model(\"../working/last_model/\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Обучаем\nhistory = model.fit(\n        train_generator,\n        steps_per_epoch = train_generator.samples//train_generator.batch_size,\n        validation_data = test_generator, \n        validation_steps = test_generator.samples//test_generator.batch_size,\n        epochs = EPOCHS,\n        callbacks = callbacks_list\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.save('../working/model_step3.hdf5')\nmodel.load_weights('best_model.hdf5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scores = model.evaluate(test_generator, verbose=1)\nprint(\"Accuracy: %.2f%%\" % (scores[1]*100))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_history(history)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"На этом этапе достигается точность порядка 0.960 - 0.965  \nИспользование LearningRateScheduler не дает заметного улучшения  \nЗатраты времени - 8 минут на эпоху, всего - 80 мин"},{"metadata":{},"cell_type":"markdown","source":"# Step 4"},{"metadata":{},"cell_type":"markdown","source":"# Big Images"},{"metadata":{},"cell_type":"markdown","source":"Увеличиваем размер подаваемых изображений, приходится уменьшать batch и резко возрастает время обсчитывания одной эпохи"},{"metadata":{"trusted":true},"cell_type":"code","source":"EPOCHS               = 5\nBATCH_SIZE           = 4 # уменьшаем batch ещё больше, иначе не влезет в память на GPU\nLR                   = 1e-6\n\nIMG_SIZE             = 512 # увеличиваем размер картинок\nIMG_CHANNELS         = 3\ninput_shape          = (IMG_SIZE, IMG_SIZE, IMG_CHANNELS)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"AUG = A.Compose([\n    A.HorizontalFlip(p=0.25),\n    A.ToGray(p=0.25),\n#    A.ToSepia(p=0.5),\n    A.OneOf([\n        A.RandomBrightnessContrast(brightness_limit=0.3, contrast_limit=0.3),\n        A.RandomBrightnessContrast(brightness_limit=0.1, contrast_limit=0.1)\n    ],p=0.5),\n    A.ShiftScaleRotate(always_apply=False, p=0.5, shift_limit=(-0.06, 0.06), rotate_limit=(-10, 10), interpolation=0, border_mode=0, value=(0, 0, 0), mask_value=None),\n#    A.GaussianBlur(p=0.05),\n#    A.HueSaturationValue(p=0.25),\n    A.RandomShadow(shadow_roi=(0, 0.5, 1, 1), num_shadows_lower=1, num_shadows_upper=2, shadow_dimension=5, always_apply=False, p=0.25),\n])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_datagen = ImageDataAugmentor(\n        rescale=1./255,\n        augment=AUG,\n        validation_split=VAL_SPLIT\n)\ntest_datagen = ImageDataAugmentor(rescale=1./255)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''train_datagen = ImageDataGenerator(\n    rescale=1. / 255,\n#    rotation_range = 5,\n#    shear_range=0.15,\n    zoom_range=[0.85,1.15],\n#    brightness_range=[0.75, 1.25],\n    width_shift_range=0.1,\n#    height_shift_range=0.1,\n    validation_split=VAL_SPLIT, # set validation split\n    horizontal_flip=False,\n#    fill_mode=\"nearest\",\n)\n\ntest_datagen = ImageDataGenerator(rescale=1. / 255)'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_generator = train_datagen.flow_from_directory(\n    PATH+'train/',       \n    target_size=(IMG_SIZE, IMG_SIZE),\n    batch_size=BATCH_SIZE,\n    class_mode='categorical',\n    shuffle=True, seed=RANDOM_SEED,\n    subset='training') \n\ntest_generator = train_datagen.flow_from_directory(\n    PATH+'train/',\n    target_size=(IMG_SIZE, IMG_SIZE),\n    batch_size=BATCH_SIZE,\n    class_mode='categorical',\n    shuffle=True, seed=RANDOM_SEED,\n    subset='validation') \n\ntest_sub_generator = test_datagen.flow_from_dataframe( \n    dataframe=sample_submission,\n    directory=PATH+'test_upload/',\n    x_col=\"Id\",\n    y_col=None,\n    shuffle=False,\n    class_mode=None,\n    seed=RANDOM_SEED,\n    target_size=(IMG_SIZE, IMG_SIZE),\n    batch_size=BATCH_SIZE,)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# загружаем модель заново на новых размерах фото\nbase_model = efn.EfficientNetB6(weights='imagenet', include_top=False, input_shape=input_shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model=M.Sequential()\nmodel.add(base_model)\nmodel.add(BatchNormalization())\nmodel.add(L.GlobalAveragePooling2D())\n#model.add(L.Dropout(0.25))\n#model.add(L.Flatten())\nmodel.add(L.Dense(256, activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(L.Dropout(0.25))     # or 0.5\nmodel.add(L.Dense(CLASS_NUM, activation='softmax'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Загружаем модель, сохраненную в предыдущую сессию\n#from tensorflow import keras\n#model = keras.models.load_model(\"../input/modelstep4last/model_step4.hdf5\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(loss=\"categorical_crossentropy\", optimizer=optimizers.Adam(lr=LR), metrics=[\"accuracy\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#model.load_weights('best_model.hdf5')\n#model.load_weights(\"../input/modelstep4last/model_step4.hdf5\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Перегружаем callbacks, чтобы убрать lr_scheduler \ncheckpoint = ModelCheckpoint('best_model.hdf5' , monitor = ['val_accuracy'] , verbose = 1  , mode = 'max')\nearlystop = EarlyStopping(monitor='val_accuracy', patience=5, restore_best_weights=True, verbose=1)\ncallbacks_list = [checkpoint, earlystop]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Обучаем\nhistory = model.fit(\n        train_generator,\n        steps_per_epoch = train_generator.samples//train_generator.batch_size,\n        validation_data = test_generator, \n        validation_steps = test_generator.samples//test_generator.batch_size,\n        epochs = EPOCHS,\n        callbacks = callbacks_list\n        )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.save('../working/model_step4.hdf5')\nmodel.load_weights('best_model.hdf5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#model.load_weights('model_step4.hdf5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scores = model.evaluate(test_generator, verbose=1)\nprint(\"Accuracy: %.2f%%\" % (scores[1]*100))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_history(history)  ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"На этом этапе достигается точность порядка 0.970 - 0.975, но есть потенциал роста при увеличении кол-ва эпох  \nЗатраты времени - 40 минут на эпоху, всего - 200 мин"},{"metadata":{},"cell_type":"markdown","source":"Завершены 4 примерно одинаковых по структуре этапа обучения нейросети, теперь проверим результат"},{"metadata":{},"cell_type":"markdown","source":"# Submission with TTA"},{"metadata":{},"cell_type":"markdown","source":"Test Time Augmentation (TTA) для усреднения нескольких предиктов и исключения случайных ошибок"},{"metadata":{"trusted":true},"cell_type":"code","source":"model.load_weights('best_model.hdf5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"AUG = A.Compose([\n    A.HorizontalFlip(p=0.25),\n    A.ToGray(p=0.25),\n    A.OneOf([\n        A.RandomBrightnessContrast(brightness_limit=0.3, contrast_limit=0.3),\n        A.RandomBrightnessContrast(brightness_limit=0.1, contrast_limit=0.1)\n    ],p=0.25),\n    A.ShiftScaleRotate(always_apply=False, p=0.5, shift_limit=(-0.06, 0.06), rotate_limit=(-10, 10), interpolation=0, border_mode=0, value=(0, 0, 0), mask_value=None),\n    A.GaussianBlur(p=0.05),\n    A.HueSaturationValue(p=0.25),\n    A.RandomShadow(shadow_roi=(0, 0.5, 1, 1), num_shadows_lower=1, num_shadows_upper=2, shadow_dimension=5, always_apply=False, p=0.25),\n])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_datagen = ImageDataAugmentor(rescale=1./255)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''test_datagen = ImageDataGenerator(\n    rescale=1. / 255,\n    rotation_range = 5,\n    shear_range=0.15,\n    zoom_range=[0.85,1.15],\n    brightness_range=[0.75, 1.25],\n    width_shift_range=0.1,\n    height_shift_range=0.1,\n#    validation_split=VAL_SPLIT, # set validation split\n    horizontal_flip=True,\n#    fill_mode=\"nearest\",\n)'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"BATCH_SIZE = 4","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_sub_generator = test_datagen.flow_from_dataframe( \n        dataframe=sample_submission,\n        directory=PATH+'test_upload/',\n        x_col=\"Id\",\n        y_col=None,\n        shuffle=False,\n        class_mode=None,\n        seed=RANDOM_SEED,\n        target_size=(IMG_SIZE, IMG_SIZE),\n        batch_size=BATCH_SIZE)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tta_steps = 5\npredictions = []\n\nfor i in range(tta_steps):\n    preds = model.predict(test_sub_generator, verbose=1) \n    predictions.append(preds)\n\npred = np.mean(predictions, axis=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = np.argmax(pred, axis=-1) #multiple categories\nlabel_map = (train_generator.class_indices)\nlabel_map = dict((v,k) for k,v in label_map.items()) #flip k,v\npredictions = [label_map[k] for k in predictions]\nfilenames_with_dir=test_sub_generator.filenames\n\nsubmission = pd.DataFrame({'Id':filenames_with_dir, 'Category':predictions}, columns=['Id', 'Category'])\nsubmission['Id'] = submission['Id'].replace('test_upload/','')\nsubmission.to_csv('submission.csv', index=False)\nprint('Save submit')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Предсказание без TTA"},{"metadata":{"trusted":true},"cell_type":"code","source":"test_sub_generator.samples","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_sub_generator.reset()\npredictions = model.predict(test_sub_generator, steps=len(test_sub_generator), verbose=1) \npredictions = np.argmax(predictions, axis=-1) #multiple categories\nlabel_map = (train_generator.class_indices)\nlabel_map = dict((v,k) for k,v in label_map.items()) #flip k,v\npredictions = [label_map[k] for k in predictions]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"filenames_with_dir=test_sub_generator.filenames\nsubmission = pd.DataFrame({'Id':filenames_with_dir, 'Category':predictions}, columns=['Id', 'Category'])\nsubmission['Id'] = submission['Id'].replace('test_upload/','')\nsubmission.to_csv('submission.csv', index=False)\nprint('Save submit')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Clean PATH\n#import shutil\n#shutil.rmtree(PATH)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Итоги:"},{"metadata":{},"cell_type":"markdown","source":"* Использована библиотека аугментации изображений Albumentations\n* Применен transfer learning с fine-tuning\n* Испробованы разные подходы к управлению LR, различные optimizer\n* Размер картинки и батч изменялись на разных этапах   \n* Сделан TTA (Test Time Augmentation)\n* Лучший достигнутый результат - 0.97558\n* BaseLine и ноутбук из учебного курса упростили выполнение задания на 80%, позволив  \n  сосредоточиться непосредственно на вычислительной части - обучении нейросети "}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}